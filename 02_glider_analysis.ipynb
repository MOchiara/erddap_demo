{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c2c588-1d5e-41bc-84fe-49a4c9952c55",
   "metadata": {},
   "source": [
    "# Example glider data analysis\n",
    "\n",
    "Once we have some glider missions of interest, we can start downloading them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcaee511-bf67-47de-b102-90617128b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from matplotlib import style\n",
    "style.use('presentation.mplstyle')\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import gsw\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b65d32a-4750-415a-9ccd-4af34b74b66d",
   "metadata": {},
   "source": [
    "### 1. Get a list of datasets of interest\n",
    "\n",
    "One can make of glider-mission combinations by examining maps and figures from the [observations portal](https://observations.voiceoftheocean.org/) and generating a list of glider missions. Alternatively, one can programatically interogate the ERDDAP itself to find datasets that match certain criteria, see [notebook 01](01_mission_filter.ipynb).\n",
    "\n",
    "Either way, you end up with a list of datasetIDs like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d464cc-d9ea-4a53-a295-981bf127cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_downloada = ['delayed_SEA068_M27', 'nrt_SEA068_M27', 'delayed_SEA069_M9',\n",
    "       'nrt_SEA069_M9', 'delayed_SEA067_M26', 'nrt_SEA067_M26',\n",
    "       'delayed_SEA067_M27', 'nrt_SEA067_M27', 'delayed_SEA067_M29',\n",
    "       'nrt_SEA067_M29', 'delayed_SEA067_M30', 'nrt_SEA067_M30',\n",
    "       'delayed_SEA067_M32', 'nrt_SEA067_M32', 'delayed_SEA067_M37',\n",
    "       'nrt_SEA067_M37', 'delayed_SEA066_M41', 'nrt_SEA066_M41',\n",
    "       'delayed_SEA066_M42', 'nrt_SEA066_M42', 'delayed_SEA066_M43',\n",
    "       'nrt_SEA066_M43']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac070e9-0e34-4fc6-b30d-e2e5548006bb",
   "metadata": {},
   "source": [
    "These are datasets that extended to > 150 m depth in the seas northeast of Gotland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d309e-c256-400f-b76c-a970d02256e2",
   "metadata": {},
   "source": [
    "### 2. Quick check with nrt datasets\n",
    "\n",
    "For preliminary analysis, I recommend downloading only the NRT (near real time) datasets, as these are ~ 100 times smaller than the delayed mode data and are much quicker to work with. To achieve this, we use the `nrt_only=True` kwarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d60fcf6e-ad5b-40b7-ad0c-7bf60f9924b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets_to_download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds_dict \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdownload_glider_dataset(\u001b[43mdatasets_to_download\u001b[49m, nrt_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets_to_download' is not defined"
     ]
    }
   ],
   "source": [
    "ds_dict = utils.download_glider_dataset(datasets_to_download, nrt_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c2294-a680-4888-89b5-0555512b268a",
   "metadata": {},
   "source": [
    "This function returns a dictionary where the keys are dataset IDs and the values are the datasets as xarray objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f088c7-e164-46ab-a771-6f7b52ba701c",
   "metadata": {},
   "source": [
    "### 3. Initial analysis\n",
    "\n",
    "Here we will create some quick plots to check that the datasets have what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc94af7-c245-4004-aa15-57702fd69ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth = 140\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for name, ds in ds_dict.items():\n",
    "    pretty_label = f'SEA0{ds.attrs[\"glider_serial\"]} M{ds.attrs[\"deployment_id\"]}'\n",
    "    ax.scatter(ds.time[ds.depth> min_depth], ds.salinity[ds.depth> min_depth], label=pretty_label, s=10)\n",
    "ax.legend()\n",
    "plt.setp(ax.get_xticklabels(), rotation=30);\n",
    "ax.set(ylabel=f\"{ds.salinity.name} ({ds.salinity.units})\", title=\"Deep salinity in the Gotland Basin\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efe718-72d1-4c4e-81b4-80b822434e74",
   "metadata": {},
   "source": [
    "A small map of the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120fd7f-791b-4ff6-b9be-de66c79542a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = cartopy.crs.AzimuthalEquidistant(central_longitude=np.mean(ds.longitude.values),\n",
    "                                  central_latitude=np.mean(ds.latitude.values))\n",
    "pc = cartopy.crs.PlateCarree()\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111, projection=coord)\n",
    "\n",
    "for name, ds in ds_dict.items():\n",
    "    pretty_label = f'SEA0{ds.attrs[\"glider_serial\"]} M{ds.attrs[\"deployment_id\"]}'\n",
    "    ax.scatter(ds.longitude.values, ds.latitude.values, transform=pc, s=10, label=pretty_label)\n",
    "lon_extend = 3\n",
    "lat_extend = 1\n",
    "lims = (np.nanmin(ds.longitude.values) - lon_extend, np.nanmax(ds.longitude.values) + lon_extend,\n",
    "        np.nanmin(ds.latitude.values) - lat_extend, np.nanmax(ds.latitude.values) + lat_extend)\n",
    "ax.set_extent(lims, crs=pc)\n",
    "\n",
    "feature = cartopy.feature.NaturalEarthFeature(name='land', category='physical',\n",
    "                                       scale='10m', edgecolor='black', facecolor='lightgreen')\n",
    "ax.add_feature(feature)\n",
    "gl = ax.gridlines(draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.top_labels = None\n",
    "gl.right_labels = None\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855ef56-5a36-477a-b5df-be13438e61ae",
   "metadata": {},
   "source": [
    "Maybe there's a geographical gradient at play too? There appears to be a bimodal distribution of salinity. Rather than a timeseries, let's plot against latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed43d4-8691-48db-890a-fcc3591a7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(2,1, figsize=(10, 10))\n",
    "for name, ds in ds_dict.items():\n",
    "    pretty_label = f'SEA0{ds.attrs[\"glider_serial\"]} M{ds.attrs[\"deployment_id\"]}'\n",
    "    ax0.scatter(ds.latitude[ds.depth> min_depth], ds.salinity[ds.depth> min_depth], label=pretty_label, s=10)\n",
    "    ax1.scatter(ds.longitude[ds.depth> min_depth], ds.salinity[ds.depth> min_depth], label=pretty_label, s=10)\n",
    "ax0.legend()\n",
    "plt.setp(ax.get_xticklabels(), rotation=30);\n",
    "ax0.set(ylabel=f\"{ds.salinity.name} ({ds.salinity.units})\", xlabel=\"latitude\")\n",
    "ax1.set(ylabel=f\"{ds.salinity.name} ({ds.salinity.units})\", xlabel=\"longitude\")\n",
    "ax0.grid()\n",
    "ax1.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11658e63-20ef-410a-bf27-8d298b97faf0",
   "metadata": {},
   "source": [
    "There's definitely some spatial vartiability here. Maybe a seperate sub-basin to the southeast? There's a ridge between them, explaining the gap in latitude of our deep data. Let's subset our data a bit before plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e066976-c557-46f3-b04b-cac8bb0949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for name, ds in ds_dict.items():\n",
    "    pretty_label = f'SEA0{ds.attrs[\"glider_serial\"]} M{ds.attrs[\"deployment_id\"]}'\n",
    "    mask = (ds.depth.values > min_depth) * (ds.latitude.values<58.4)\n",
    "    ax.scatter(ds.time[mask], ds.salinity[mask], label=pretty_label, s=10)\n",
    "ax.legend()\n",
    "plt.setp(ax.get_xticklabels(), rotation=30);\n",
    "ax.set(ylabel=f\"{ds.salinity.name} ({ds.salinity.units})\", title=\"Deep salinity in the southern Gotland Basin\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbfdc8-be49-4c0a-8db2-94b7a2cfbba1",
   "metadata": {},
   "source": [
    "### 4. Download the full datasets\n",
    "\n",
    "Once we are confident that the dataset contain something of interest, we can download the full size delayed mode datasets. This uses a cache of data in the directory `voto_erddap_data_cache` to avoid duplicate downloads.\n",
    "\n",
    "**To force data to re-download, simply delete the cache dir**. You should do this periodically to get the most up to date datasets\n",
    "\n",
    "\n",
    "Delayed mode datasets are big! To speed up the download, and reduce the load on the server, we can specify just the variables that we want and the server-side subsetting of depth. We use the `variables` and `constraints` kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c076869-082f-4c57-8688-b2bf712f6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "     'latitude',\n",
    "     'longitude',\n",
    "     'time',\n",
    "     'depth',\n",
    "     'profile_direction',\n",
    "     'profile_index',\n",
    "     'salinity',\n",
    "     'salinity_qc']\n",
    "\n",
    "constraints = {\"depth>=\": 140,\n",
    "              \"latitude>=\": 58.4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d707ed-04ef-4d62-af6d-76b2d08b1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_delayed = utils.download_glider_dataset(datasets_to_download, delayed_only=True,\n",
    "                                          variables=variables, constraints=constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddf377-6a89-4b1c-9e67-ed4b0b7af7c6",
   "metadata": {},
   "source": [
    "To demonstrate, here I delete one of the cached datasets then call the download function again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b38885-909a-41e0-a561-a8cfbf24203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm voto_erddap_data_cache/delayed_SEA069_M9.nc\n",
    "ds_delayed = utils.download_glider_dataset(datasets_to_download, delayed_only=True,\n",
    "                                          variables=variables, constraints=constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eea2c2-7a90-4dbe-9cb0-93d13bb00a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for name, ds in ds_delayed.items():\n",
    "    pretty_label = f'SEA0{ds.attrs[\"glider_serial\"]} M{ds.attrs[\"deployment_id\"]}'\n",
    "    ax.scatter(ds.time, ds.salinity, label=pretty_label, s=10)\n",
    "ax.legend()\n",
    "plt.setp(ax.get_xticklabels(), rotation=30);\n",
    "ax.set(ylabel=f\"{ds.salinity.name} ({ds.salinity.units})\",\n",
    "       xlim=(datetime.date(2022,4,1), datetime.date(2023,2,1)),\n",
    "       title=\"Deep salinity in the southern Gotland Basin\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ed2cb-3f9e-4dc5-8b08-cf0d68bba7c2",
   "metadata": {},
   "source": [
    "Using the delayed mode datasets we have data at much higher temporal resolution, but we lack the most up to date data, as we need to physically recover the gliders to get the delayed mode data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20571e57-8ca2-48d9-8081-069911b94b38",
   "metadata": {},
   "source": [
    "### 5. Combine datasets\n",
    "\n",
    "from the [VOTO stats page](https://observations.voiceoftheocean.org/stats) we see that SEA067 completed three back to back missions in the Gotland basin during April - June 2022\n",
    "\n",
    "![observations gantt plot](https://observations.voiceoftheocean.org/static/img/glider/gantt_all_ops.png)\n",
    "\n",
    "Using this information, we can be confident in combining those missions (M26, M27, M29) into one dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5d00e-92f2-401d-8d17-869a5a60b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gotland = xr.concat((ds_delayed[\"delayed_SEA067_M26\"], ds_delayed[\"delayed_SEA067_M27\"], ds_delayed[\"delayed_SEA067_M29\"]), dim='obs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33886b6a-3747-4905-aa48-ef5d76b8afab",
   "metadata": {},
   "source": [
    "We can now create plots from one dataset, rather than looping through several individual ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74172bd3-4486-4f5b-91c7-917ee53362c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth = 140\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "col = ax.scatter(ds_gotland.time[ds_gotland.depth> min_depth], ds_gotland.salinity[ds_gotland.depth> min_depth], c=ds_gotland.latitude[ds_gotland.depth> min_depth],s=10)\n",
    "plt.setp(ax.get_xticklabels(), rotation=30);\n",
    "fig.colorbar(ax=ax, mappable=col, label=\"latitude\")\n",
    "ax.set(ylabel=f\"{ds.salinity.name} ({ds.salinity.units})\", title=\"Deep salinity in the Gotland Basin - SEA056\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60259997-a425-4971-8dc0-6ae2365d5b07",
   "metadata": {},
   "source": [
    "------------------------\n",
    "\n",
    "# Miscellaneous tips\n",
    "\n",
    "- To save time and avoid reprocessing from scratch each time, you can always save your xarray dataset with `ds.to_netcdf(\"/path/filename.nc\")` and load it back in with `ds = xr.open_dataset(\"/path/filename.nc\")`. *However* ensure that your workflow can recreate your results from the data download onward, so that any changes to the orginal datasets (more data in NRT, better QC etc.) can be incorporated into your analysis\n",
    "- Save figures with `fig.savefig(\"figures/fig_name.png\")`\n",
    "- You can save download time and disk space by downloading only the variables you need. Pass them as a list to `utils.download_glider_dataset`. Similarly, you can pass a dictionary of constraints\n",
    "- To force a re-run from fresh data, delete the `voto_erddap_data_cache` directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
